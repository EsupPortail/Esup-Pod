---
layout: default
version: 4.x
lang: fr
---

# Infrastructure Pod v4 √† l'Universit√© de Montpellier (UM)

## Contexte

|                         | Commentaires          |
|-------------------------|-----------------------|
| **Date de r√©alisation** | Juillet 2025          |
| **Version de Pod**      | Pod v4.0.0            |
| **Auteur**              | Lo√Øc Bonavent         |

## Pr√©sentation de l'infrastructure de production

![Infrastructure Pod v4 √† l'UM](um/architecture.png)

Cette infrastructure repose sur l'utilisation de :

- **1 load balancer HAProxy** : ce load balancer est utilis√© √† l'universit√© pour quasiment l'ensemble des sites Web.
- **2 serveurs Web** : utiliser deux serveurs web en frontal renforce la s√©curit√© et la disponibilit√©, en r√©partissant la charge et en √©vitant les points de d√©faillance uniques.<br>
  _Briques install√©es sur ces serveurs Web : Pod, Nginx, uWSGI._
- **1 serveur principal** : ce serveur - nomm√© principal pour le diff√©rencier des autres - correspond √† un serveur d'encodage d√©port√© pour lequel REDIS et Elasticsearch sont install√©s.<br>
  _Briques install√©es sur ces serveurs Web : Pod, REDIS, Elasticsearch, Celery (1 worker), ffmpeg, Whisper._
- **3 serveurs d'encodage** : serveurs d'encodage d√©port√©s purs, principalement utilis√©s pour la transcription (qui ne peut encore √™tre r√©alis√©e sur les serveurs GPU - depuis 2025, ~17% des vid√©os sont transcrites) et pour l'encodage des vid√©os dont le format n'est pas g√©r√© par les serveurs GPU.<br>
  _Briques install√©es sur ces serveurs Web : Pod, Celery (1 worker), ffmpeg, Whisper._
- **1 base de donn√©es** : base de donn√©es MariaDB mutualis√©e.
- **1 serveur de fichiers** : serveur de fichiers partag√© NFS d'une taille de 50To, dont 40To est occup√© actuellement.

_Tous les serveurs tournent sur Debian 12._

> üí° Cette infrastructure ne tient pas compte des serveurs RTMP Nginx, pour la gestion des directs (cf. documentation pour la mise en place du direct live), et des serveurs d'encodage GPU qui reposent sur du sp√©cifique UM.

> Chaque serveur d'encodage utilise 16 Go RAM et 16 vCPU car j'utilise la transcription via **Whisper** et son mod√®le **Medium**, qui est tr√®s performant mais qui consomme quand m√™me quelques ressources.
>
> Pour le serveur principal, ces ressources sont n√©cessaires pour faire tourner REDIS, Elasticsearch et Whisper en m√™me temps, et √©viter tout probl√®me (style Out Of Memory...).
>
> Pour les autres serveurs d'encodage, c'est peut-√™tre quelque peu surdimensionn√© (8/12 Go RAM et 8/12 vCPU devraient √™tre suffisants).
{: .alert .alert-warning}

## Installation

> N'ayant toujours pas d'orchestrateurs de conteneurs √† l'universit√©, j'ai r√©alis√© l'installation "√† l'ancienne", en utilisant principalement la [documentation du mode Stand Alone](../install_standalone_fr)
>
> Avec cette documentation et les autres, si l'infrastructure est pr√©sente et s'il n'y a pas de _probl√®mes d'environnement_ (firewall, privil√®ges sur la base de donn√©es...), cela ne n√©cessite que quelques heures.
>
> Personnellement, j'utilise **SuperPutty** pour ex√©cuter des commandes sur plusieurs serveurs √† la fois (typiquement l'installation de Pod v4 sur tous les serveurs d'encodage).
>
> Certaines √©tapes de la proc√©dure suivante peuvent √™tre r√©alis√©es en parall√®le ou dan un ordre diff√©rent, selon votre convenance.

---

### Etape 1 : Installation de Pod v4

|                        | Commentaires                                      |
|------------------------|---------------------------------------------------|
| **Serveurs concern√©s** | Tous les serveurs Pod (Web, principal, d'encodage)|
| **Documentations de r√©f√©rence** | [Documentation du mode Stand Alone / Environnement](../install_standalone_fr#environnement)|
{: .table .table-striped}

J'ai suivi rigoureusement la documentation **[Installation d‚ÄôEsup-Pod en mode Stand Alone / Environnement](../install_standalone_fr#environnement)**.

> Sp√©cificit√© UM :
> Vis-√†-vis de l'ancienne infrastructure, j'ai conserv√© le m√™me **identifiant Linux** pour le user `pod`, via la commande :
>
> ```sh
> user@pod:~$ usermod -u 1313 pod
> ```

Concernant le fichier de configuration `settings_local.py`, une version finale est disponible en fin de cette documentation.

üéØ A la fin de cette √©tape, Pod v4 est install√© sur tous les serveurs Pod, avec toutes ses librairies Python.
{: .alert .alert-primary}

### Etape 2 : Configuration et utilisation d'une base de donn√©es MySQL/MariaDB

|                        | Commentaires                                      |
|------------------------|---------------------------------------------------|
| **Serveurs concern√©s** | Tous serveurs Pod (Web, principal, d'encodage) |
| **Documentations de r√©f√©rence** | [Configuration et utilisation d'une base de donn√©es MySQL/MariaDB](../mariadb_fr)|
{: .table .table-striped}

Pour configurer et utiliser une base de donn√©es MySQL/MariaDB sur tous les serveurs Pod, j'ai suivi la documentation concernant la **[configuration et utilisation d'une base de donn√©es MySQL/MariaDB](../mariadb_fr)**.

Au vue de l'architecture, j'ai remplac√© `<my_database_host>` par **l'adresse IP du serveur de base de donn√©es** et les autres variables `<my_database_*>` par les valeurs de mon environnement.

> üí° Si vous souhaitez installer un serveur MySQL/MariaDB, il faut suivre la documentation concernant **[l'installation, la configuration et utilisation d'une base de donn√©es MySQL/MariaDB](../production-mode_fr#base-de-donn√©es-mysqlmariadb)**.

üéØ A la fin de cette √©tape, tous les serveurs Pod peuvent utiliser la base de donn√©es de type MySQL/MariaDB.
{: .alert .alert-primary}

### Etape 3 : Installation de REDIS

|                        | Commentaires                                      |
|------------------------|---------------------------------------------------|
| **Serveurs concern√©s** | Serveur principal |
| **Documentations de r√©f√©rence** | [Documentation du mode Stand Alone / Redis](../install_standalone_fr#redis)|
{: .table .table-striped}

Pour installer REDIS sur le serveur principal, j'ai suivi la **[documentation du mode Stand Alone / Redis](../install_standalone_fr#redis)**.

Au vue de l'architecture, j'ai remplac√© partout `<my_redis_host>` par **l'adresse IP du serveur REDIS**, obtenu par `hostname -I` sur le serveur principal et j'ai √©dit√© le fichier _/etc/redis/redis.conf_ avec ces informations :

```sh
bind <my_redis_host>
protected-mode no
```

üéØ A la fin de cette √©tape, REDIS est install√© sur le serveur principal de Pod.
{: .alert .alert-primary}

### Etape 4 : Configuration et utilisation de REDIS

|                        | Commentaires                                      |
|------------------------|---------------------------------------------------|
| **Serveurs concern√©s** | Tous serveurs Pod (Web, principal, d'encodage) |
| **Documentations de r√©f√©rence** | [Configuration et usage de REDIS](../redis_fr)|
{: .table .table-striped}

Pour configurer et utiliser REDIS sur tous les serveurs Pod, j'ai suivi la documentation concernant la **[configuration et usage de REDIS](../redis_fr)**.

üéØ A la fin de cette √©tape, REDIS peut √™tre utilis√© par l'ensemble des serveurs Pod.
{: .alert .alert-primary}

### Etape 5 : Installation d'Elasticsearch

|                        | Commentaires                                      |
|------------------------|---------------------------------------------------|
| **Serveurs concern√©s** | Serveur principal |
| **Documentations de r√©f√©rence** | [Documentation du mode Stand Alone / Elasticsearch](../install_standalone_fr#elasticsearch)|
{: .table .table-striped}

Pour installer Elasticsearch sur le serveur principal, j'ai suivi la **[documentation du mode Stand Alone / Elasticsearch](../install_standalone_fr#elasticsearch)** avec le _mode Security d'ES8_ activ√©.

Au vue de l'architecture, j'ai remplac√© partout `<my_es_host>` par **l'adresse IP du serveur Elasticsearch**, obtenu par `hostname -I` sur le serveur principal et j'ai √©dit√© le fichier _/etc/elasticsearch/elasticsearch.yml_ avec ces informations :

```yml
cluster.name: pod-application
node.name: pod-1
network.host: <my_es_host>
discovery.seed_hosts: ["<my_es_host>"]
cluster.initial_master_nodes: ["pod-1"]

xpack.security.enabled: true
xpack.security.enrollment.enabled: true
xpack.security.transport.ssl:
  enabled: true
  verification_mode: certificate
  keystore.path: certs/transport.p12
  truststore.path: certs/transport.p12
http.host: 0.0.0.0
xpack.security.http.ssl.enabled: true
xpack.security.http.ssl.verification_mode: certificate
xpack.security.http.ssl.keystore.path: /etc/elasticsearch/elastic-certificates.p12
xpack.security.http.ssl.truststore.path: /etc/elasticsearch/elastic-certificates.p12
```

üéØ A la fin de cette √©tape, Elasticsearch est install√© sur le serveur principal de Pod.
{: .alert .alert-primary}

### Etape 6 : Installation des d√©pendances

|                        | Commentaires                                      |
|------------------------|---------------------------------------------------|
| **Serveurs concern√©s** | Tous serveurs Pod (Web, principal, d'encodage) |
| **Documentations de r√©f√©rence** | [Documentation du mode Stand Alone / Installation des d√©pendances](../install_standalone_fr#installation-des-d√©pendances)|
{: .table .table-striped}

Pour installer les d√©pendances sur tous les serveurs Pod, j'ai suivi la **[documentation du mode Stand Alone / Installation des d√©pendances](../install_standalone_fr#installation-des-d√©pendances)**.

> Logiquement, ces d√©pendances ne concernent que les serveurs Web, mais je pr√©f√®re les installer sur l'ensemble des serveurs au cas o√π.
{: .alert .alert-secondary}

üéØ A la fin de cette √©tape, les d√©pendances de Pod sont install√©s sur tous les serveurs Pod.
{: .alert .alert-primary}

### Etape 7 : Installation du syst√®me Web reposant sur NGINX/uWSGI et param√©trage

|                        | Commentaires                                      |
|------------------------|---------------------------------------------------|
| **Serveurs concern√©s** | Serveurs Web |
| **Documentations de r√©f√©rence** | [Frontal Web Nginx / uWSGI et fichiers statiques](../production-mode_fr#frontal-web-nginx--uwsgi-et-fichiers-statiques)|
{: .table .table-striped}

Pour installer, configurer et utiliser Nginx/uWSGI sur tous les serveurs Web, j'ai suivi la documentation concernant la mise en place de **[Frontal Web Nginx / UWSGI et fichiers statiques](../production-mode_fr#frontal-web-nginx--uwsgi-et-fichiers-statiques)**.

> Sp√©cificit√© UM :
> Vis-√†-vis de l'ancienne infrastructure, j'ai conserv√© le m√™me **identifiant Linux** pour le groupe `www-data` que celui du groupe `nginx`, et j'ai ajout√© le user `pod` √† ce groupe via les commandes :
>
> ```sh
> user@pod:~$ sudo groupmod -g 989 www-data
> user@pod:~$ sudo usermod -g www-data pod
> ```

üéØ A la fin de cette √©tape, les serveurs Web reposant sur Nginx / UWSGI sont op√©rationnels.
{: .alert .alert-primary}

### Etape 8 : Installation du syst√®me d'encodage

|                        | Commentaires                                      |
|------------------------|---------------------------------------------------|
| **Serveurs concern√©s** | Serveurs d'encodage, serveur principal |
| **Documentations de r√©f√©rence** | [Documentation pour d√©porter l‚Äôencodage sur un ou plusieurs serveurs](../remote-encoding_fr)|
{: .table .table-striped}

> L'encodage peut se r√©aliser de diff√©rentes mani√®res; pour ma part, √† l'heure actuelle, j'utilise le syst√®me d'encodage d√©port√©, sans utilisation de microservices.
{: .alert .alert-light}

Pour installer ce syst√®me d'encodage, j'ai suivi la **[documentation pour d√©porter l‚Äôencodage sur un ou plusieurs serveurs](../remote-encoding_fr)**.

Cela implique l'utilisation de REDIS du serveur principal et de Celery sur les serveurs d'encodage.

üéØ A la fin de cette √©tape, les serveurs d'encodage, reposant sur **REDIS** et du **Celery**, sont fonctionnels.
{: .alert .alert-primary}

### Etape 9 : Installation du syst√®me de transcription

|                        | Commentaires                                      |
|------------------------|---------------------------------------------------|
| **Serveurs concern√©s** | Serveurs d'encodage |
| **Documentations de r√©f√©rence** | [Documentation concernant l'installation de l'autotranscription](../optional/auto-transcription-install_fr)|
{: .table .table-striped}

> L'autotranscription peut se r√©aliser de diff√©rentes mani√®res; pour ma part, √† l'heure actuelle, j'utilise le syst√®me d'autotranscription d√©port√©, sans utilisation de microservices.
{: .alert .alert-light}

Pour installer ce syst√®me d'autotranscription, j'ai suivi la **[documentation concernant l'installation de l'autotranscription](../optional/auto-transcription-install_fr)** et utiliser **Whisper** avec le mod√®le `medium`.

üéØ A la fin de cette √©tape, les serveurs d'encodage peuvent r√©aliser des transcriptions.
{: .alert .alert-primary}

### Etape 10 : Personnalisation visuelle

|                        | Commentaires                                      |
|------------------------|---------------------------------------------------|
| **Serveurs concern√©s** | Serveurs Web |
| **Documentations de r√©f√©rence** | [Documentation concernant la personnalisation visuelle](../visual-customisation_fr)|
{: .table .table-striped}

Pour r√©aliser la personnalisation visuelle pour mon √©tablissement, j'ai suivi la **[documentation concernant la personnalisation visuelle](../visual-customisation_fr)**.

> A l'universit√© de Montpellier, j'ai repris les √©lements d√©j√† r√©alis√©s pour Pod v3.

üéØ A la fin de cette √©tape, le site Web Pod v4 sera √† la charte graphique de votre √©tablissement.
{: .alert .alert-primary}

---

Apr√®s avoir suivi ces √©tapes, l'environnement Pod de production est install√©.
